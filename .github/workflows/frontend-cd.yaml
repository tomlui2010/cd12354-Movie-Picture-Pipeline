name: Frontend Continuous Deployment
on: 
  # push:
  #   branches:
  #     - main
  #   paths:
  #     - 'setup/frontend/**'
  workflow_dispatch:
  # workflow_run:
  #   workflows: ["Backend Continuous Deployment"]  # Wait until backend workflow has completes
  #   types:
  #     - completed
jobs:  
  frontend-cd-lint:  
    name: frontend-cd-lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        
      - name: Use Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Cache node modules
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: v1-npm-deps-${{ hashFiles('**/package-lock.json') }}
          restore-keys: v1-npm-deps-

      - name: Install the dependencies.
        run: |
          cd starter/frontend && npm ci  

      - name: Run lint
        run: |
          cd starter/frontend
          npm run lint
        continue-on-error: false
      
      - name: Run hadolint for dockerile
        run: |
          sudo wget -O /usr/local/bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.16.3/hadolint-Linux-x86_64 && sudo chmod +x /usr/local/bin/hadolint
          /usr/local/bin/hadolint starter/frontend/Dockerfile
        continue-on-error: false

  frontend-cd-test:   
    name: frontend-cd-test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        
      - name: Use Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Cache node modules
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: v1-npm-deps-${{ hashFiles('**/package-lock.json') }}
          restore-keys: v1-npm-deps-

      - name: Install the dependencies.
        run: |
          cd starter/frontend
          npm ci  

      - name: Run test
        run: | 
          cd starter/frontend
          npm test

  create-infra:
    name: create-infra
    needs: 
      - frontend-cd-test
      - frontend-cd-lint
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up AWS CLI
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ vars.AWS_REGION }}

    - name: Check if EKS Cluster is Active
      id: check_eks_status
      run: |
        eks_status=$(aws eks describe-cluster --name ${{ vars.CLUSTER_NAME }} --region ${{ vars.AWS_REGION }} --query "cluster.status" --output text)
        echo "EKS cluster status: $eks_status"
        if [ "$eks_status" == "ACTIVE" ]; then
          echo "::set-output name=is_active::true"
        else
          echo "::set-output name=is_active::false"
        fi

    - name: Set up Terraform
      if: steps.check_eks_status.outputs.is_active == 'false'
      uses: hashicorp/setup-terraform@v1
      with:
        terraform_version: 1.3.9

    - name: Terraform Init
      if: steps.check_eks_status.outputs.is_active == 'false'
      run: cd setup/terraform && terraform init

    - name: Terraform Validate
      if: steps.check_eks_status.outputs.is_active == 'false'
      run: cd setup/terraform && terraform validate 

    - name: Terraform Plan
      if: steps.check_eks_status.outputs.is_active == 'false'
      run: cd setup/terraform && terraform plan -var "aws_default_region=${{ vars.AWS_REGION }}" -var "aws_account_id=${{ vars.AWS_ACCOUNT_ID }}" -var "github_pat=${{ secrets.TOKEN_GITHUB }}"
      continue-on-error: true

    - name: Terraform Apply
      if: steps.check_eks_status.outputs.is_active == 'false'
      run: |
        cd setup/terraform && terraform apply -auto-approve -var "aws_default_region=${{ vars.AWS_REGION }}" -var "aws_account_id=${{ vars.AWS_ACCOUNT_ID }}" -var "github_pat=${{ secrets.TOKEN_GITHUB }}"

    - name: Terraform Destroy on Failure
      if: failure() && steps.check_eks_status.outputs.is_active == 'false'
      run: terraform destroy -auto-approve -refresh=false -var "aws_default_region=${{ vars.AWS_REGION }}" -var "aws_account_id=${{ vars.AWS_ACCOUNT_ID }}" -var "github_pat=${{ secrets.TOKEN_GITHUB }}"
      working-directory: ./setup/terraform

    - name: Upload Terraform State
      if: success() && steps.check_eks_status.outputs.is_active == 'false'
      uses: actions/upload-artifact@v3
      with:
        name: terraform-state
        path: setup/terraform/terraform.tfstate

  wait_for_eks:
    runs-on: ubuntu-latest
    needs: create-infra
    steps:
      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Check EKS Cluster Status
        run: |
          aws eks describe-cluster --name ${{vars.CLUSTER_NAME}} --region ${{vars.AWS_REGION}} | jq -e '.cluster.status == "ACTIVE"' > /dev/null
        continue-on-error: false

  frontend-cd-build:    
    name: frontend-cd-build
    needs: 
    - wait_for_eks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        
      - name: Use Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Cache node modules
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: v1-npm-deps-${{ hashFiles('**/package-lock.json') }}
          restore-keys: v1-npm-deps-

      - name: Install the dependencies.
        run: |
          cd starter/frontend && npm ci

      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}


      - name: Read externalip from S3 bucket
        run: |
          aws s3 cp s3://${{ vars.AWS_ACCOUNT_ID }}/externalip.txt .
          EXTERNALIP=$(cat externalip.txt | grep EXTERNALIP | cut -d '=' -f2)
          echo "EXTERNALIP=${EXTERNALIP}" >> $GITHUB_ENV
      
      - name: Trigger CodeBuild
        env:
          PROJECT_NAME: udacity
        run: |
          aws codebuild start-build --project-name $PROJECT_NAME --environment-variables-override name=AWS_DEFAULT_REGION,value=${{vars.AWS_REGION}} name=AWS_ACCOUNT_ID,value=${{vars.AWS_ACCOUNT_ID}} name=APP_NAME,value=frontend name=BACKEND_URL,value=$EXTERNALIP

  wait_for_codebuild:
    runs-on: ubuntu-latest
    needs: frontend-cd-build
    steps:
      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Fetch and wait for CodeBuild success
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ vars.AWS_REGION }}
          PROJECT_NAME: "udacity"
        run: |
          # Fetch the latest build ID
          build_id=$(aws codebuild list-builds-for-project --project-name $PROJECT_NAME --max-items 1 | jq -r '.ids[0]')

          # Check if build ID was fetched successfully
          if [ -z "$build_id" ]; then
            echo "No build ID found for the project."
            exit 1
          fi

          echo "Latest build ID: $build_id"

          # Loop to wait for build completion
          while true; do
            build_status=$(aws codebuild batch-get-builds --ids "$build_id" --query 'builds[0].buildStatus' --output text)

            if [ "$build_status" == "SUCCEEDED" ]; then
              echo "Build succeeded!"
              break
            elif [ "$build_status" == "FAILED" ]; then
              echo "Build failed."
              exit 1
            elif [ "$build_status" == "IN_PROGRESS" ]; then
              echo "Build still in progress, checking again in 30 seconds..."
              sleep 30
            else
              echo "Build encountered an unexpected status: $build_status"
              exit 1
            fi
          done
        continue-on-error: false

  frontend-cd-deploy:
    name: frontend-cd-deploy
    runs-on: ubuntu-latest
    needs: 
      - create-infra
      - wait_for_codebuild
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: v1.29.0

      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Generate Kubeconfig
        run: |
          CLUSTER_NAME=$(aws eks list-clusters --region ${{ vars.AWS_REGION }} --query "clusters[0]" --output text)
          echo "Cluster Name: $CLUSTER_NAME"
          aws eks update-kubeconfig --region ${{ vars.AWS_REGION }} --name $CLUSTER_NAME

      - name: Setup Kustomize
        uses: imranismail/setup-kustomize@v2

      - name: Deploy frontend App
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ vars.AWS_REGION }}
        run: |
          cd starter/frontend/k8s
          FRONTEND_ECR=$(aws ecr describe-repositories --repository-names frontend --query 'repositories[*].[repositoryUri]' --output text)
          kustomize edit set image frontend=$FRONTEND_ECR:${{ github.sha }}
          kustomize build | kubectl apply -f -
